{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Pytorch? \n",
    "\n",
    "1. Eager execution (Graph is constructed in a dynamic way)\n",
    "2. Tensor library with GPU acceleration\n",
    "3. Simplicity\n",
    "4. Ease of moving from research to production (python to C++)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some tensor operations and their properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3404,  0.8985,  0.3675],\n",
      "        [ 0.5315,  0.8720,  0.0051],\n",
      "        [ 0.1406,  0.3545,  0.1580],\n",
      "        [ 0.2726,  0.4869,  0.1328],\n",
      "        [ 0.9369,  0.7303,  0.3762]])\n",
      "tensor([[ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.]])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# Everything in torch is a tensor, with an implicit data type, device location\n",
    "rand_x = torch.rand(5, 3)\n",
    "print(rand_x)\n",
    "zeros = torch.zeros_like(rand_x)\n",
    "print(zeros)\n",
    "print(rand_x.shape)\n",
    "print(rand_x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3404,  1.8985,  1.3675],\n",
      "        [ 1.5315,  1.8720,  1.0051],\n",
      "        [ 1.1406,  1.3545,  1.1580],\n",
      "        [ 1.2726,  1.4869,  1.1328],\n",
      "        [ 1.9369,  1.7303,  1.3762]])\n",
      "tensor([[ 1.3404,  1.8985,  1.3675],\n",
      "        [ 1.5315,  1.8720,  1.0051],\n",
      "        [ 1.1406,  1.3545,  1.1580],\n",
      "        [ 1.2726,  1.4869,  1.1328],\n",
      "        [ 1.9369,  1.7303,  1.3762]])\n",
      "Before addition x was tensor([[ 0.3404,  0.8985,  0.3675],\n",
      "        [ 0.5315,  0.8720,  0.0051],\n",
      "        [ 0.1406,  0.3545,  0.1580],\n",
      "        [ 0.2726,  0.4869,  0.1328],\n",
      "        [ 0.9369,  0.7303,  0.3762]])\n",
      "tensor([[ 1.3404,  1.8985,  1.3675],\n",
      "        [ 1.5315,  1.8720,  1.0051],\n",
      "        [ 1.1406,  1.3545,  1.1580],\n",
      "        [ 1.2726,  1.4869,  1.1328],\n",
      "        [ 1.9369,  1.7303,  1.3762]])\n"
     ]
    }
   ],
   "source": [
    "# tensor operations\n",
    "y = torch.ones_like(rand_x, dtype=torch.float)\n",
    "print(rand_x + y)\n",
    "print(torch.add(rand_x, y))\n",
    "print(\"Before addition x was\", rand_x)\n",
    "rand_x.add_(y) # inplace addition !!! changes values of rand_x\n",
    "print(rand_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.8985,  1.8720,  1.3545,  1.4869,  1.7303]) tensor([ 1.1406,  1.3545,  1.1580]) tensor([[ 1.3404,  1.8985],\n",
      "        [ 1.5315,  1.8720],\n",
      "        [ 1.1406,  1.3545]])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# indexing\n",
    "print(rand_x[:, 1], rand_x[2, :], rand_x[:3, :2]) # numpy like indexing :)\n",
    "# resizing\n",
    "view_x = rand_x.view(1, -1) # tensor.view(a, b) will return a new tensor, recommended method\n",
    "reshaped_x = rand_x.reshape(1, -1) # tensor.reshape(a, b) will return a new tensor\n",
    "print(rand_x.size())\n",
    "resized_x = rand_x.resize_(1, -1) # since tensor.resize_(a, b) is inplace operations, it changes the values of x, upredictable\n",
    "print(rand_x.size()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 15])\n",
      "torch.Size([1, 15])\n",
      "tensor([ 1.3404])\n"
     ]
    }
   ],
   "source": [
    "print(view_x.size())\n",
    "print(reshaped_x.size())\n",
    "print(resized_x) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]] <class 'numpy.ndarray'>\n",
      "tensor([[ 6.,  6.,  6.,  6.,  6.],\n",
      "        [ 6.,  6.,  6.,  6.,  6.],\n",
      "        [ 6.,  6.,  6.,  6.,  6.],\n",
      "        [ 6.,  6.,  6.,  6.,  6.],\n",
      "        [ 6.,  6.,  6.,  6.,  6.]])\n",
      "[[6. 6. 6. 6. 6.]\n",
      " [6. 6. 6. 6. 6.]\n",
      " [6. 6. 6. 6. 6.]\n",
      " [6. 6. 6. 6. 6.]\n",
      " [6. 6. 6. 6. 6.]]\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# numpy bridge\n",
    "y = torch.ones(5, 5, dtype=torch.float)\n",
    "print(type(y))\n",
    "np_y = y.numpy() # tensor.numpy()  returns the numpy equivalent of same tensor sharing a common memory location\n",
    "print(np_y, type(np_y))\n",
    "\n",
    "y.add_(5) # changing y also impacts np_y since they share a common memory location\n",
    "print(y)\n",
    "print(np_y)\n",
    "\n",
    "# numpy to tensor\n",
    "tensor_y = torch.from_numpy(np_y)\n",
    "print(type(tensor_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([[ 5.8328,  6.9538,  6.6606,  4.9969,  7.1488],\n",
      "        [ 6.8675,  5.7050,  4.9898,  7.1841,  4.6847],\n",
      "        [ 5.8786,  7.7159,  5.8238,  6.9145,  6.1509],\n",
      "        [ 8.0610,  5.4459,  5.6590,  5.4418,  6.6304],\n",
      "        [ 6.8168,  7.6326,  6.9963,  7.1424,  6.4644]], device='cuda:0')\n",
      "tensor([[ 5.8328,  6.9538,  6.6606,  4.9969,  7.1488],\n",
      "        [ 6.8675,  5.7050,  4.9898,  7.1841,  4.6847],\n",
      "        [ 5.8786,  7.7159,  5.8238,  6.9145,  6.1509],\n",
      "        [ 8.0610,  5.4459,  5.6590,  5.4418,  6.6304],\n",
      "        [ 6.8168,  7.6326,  6.9963,  7.1424,  6.4644]])\n"
     ]
    }
   ],
   "source": [
    "# moving tensors to CUDA and CPU\n",
    "print(torch.cuda.is_available()) # checks whether there is a cuda device available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") # cuda object\n",
    "    x = torch.randn(5, 5, device=device) # creating a new tensor on this device\n",
    "    y = y.to(device) # moving y to cuda\n",
    "    z = x + y # adding taking on cuda device\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\")) # moving the tensor to cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
